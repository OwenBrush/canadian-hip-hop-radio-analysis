{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.metrics.pairwise import haversine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owen/Programs/anaconda3/envs/lighthouse/lib/python3.8/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WEEK OF</th>\n",
       "      <th>STATION</th>\n",
       "      <th>STATION CITY</th>\n",
       "      <th>STATION PROVINCE</th>\n",
       "      <th>STATION LATITUDE</th>\n",
       "      <th>STATION LONGITUDE</th>\n",
       "      <th>CHART POSITION</th>\n",
       "      <th>ARTIST NAME(S)</th>\n",
       "      <th>ARTIST COUNTRY</th>\n",
       "      <th>ARTIST HOME CITY</th>\n",
       "      <th>...</th>\n",
       "      <th>LABEL TYPE</th>\n",
       "      <th>LANGUAGE OF MUSIC</th>\n",
       "      <th>VISIBLE ETHNIC MINORITY</th>\n",
       "      <th>CENSUS RACE CLASSIFICATION</th>\n",
       "      <th>ARTIST GENDER</th>\n",
       "      <th>M-MUSIC</th>\n",
       "      <th>A-ARTIST</th>\n",
       "      <th>P-PERFORMANCE</th>\n",
       "      <th>L-LYRICS</th>\n",
       "      <th>Unnamed: 24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-10 00:00:00</td>\n",
       "      <td>CJSR</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>AB</td>\n",
       "      <td>53.55</td>\n",
       "      <td>-113.5</td>\n",
       "      <td>4</td>\n",
       "      <td>Breakestra</td>\n",
       "      <td>US</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>Indie</td>\n",
       "      <td>English</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mixed Group</td>\n",
       "      <td>Male Group</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               WEEK OF STATION STATION CITY STATION PROVINCE  \\\n",
       "0  2006-01-10 00:00:00    CJSR     Edmonton               AB   \n",
       "\n",
       "   STATION LATITUDE  STATION LONGITUDE CHART POSITION ARTIST NAME(S)  \\\n",
       "0             53.55             -113.5              4    Breakestra    \n",
       "\n",
       "  ARTIST COUNTRY ARTIST HOME CITY  ... LABEL TYPE LANGUAGE OF MUSIC  \\\n",
       "0             US  Los Angeles, CA  ...      Indie           English   \n",
       "\n",
       "   VISIBLE ETHNIC MINORITY CENSUS RACE CLASSIFICATION ARTIST GENDER M-MUSIC  \\\n",
       "0                      Yes                Mixed Group    Male Group      No   \n",
       "\n",
       "  A-ARTIST  P-PERFORMANCE L-LYRICS Unnamed: 24  \n",
       "0        No            No       No         NaN  \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"Canadian Radio Playlist_V.21.xlsx\", \"Campus Radio Charts\")\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop empty column\n",
    "clean_df = df.drop('Unnamed: 24', axis=1)\n",
    "# Convert place holder strings into nan values\n",
    "clean_df.replace(['',' ', '-', '?','- ','? '], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WEEK OF                          267\n",
       "STATION                           26\n",
       "STATION CITY                      21\n",
       "STATION PROVINCE                   7\n",
       "STATION LATITUDE                  21\n",
       "STATION LONGITUDE                 21\n",
       "CHART POSITION                    10\n",
       "ARTIST NAME(S)                  2165\n",
       "ARTIST COUNTRY                     6\n",
       "ARTIST HOME CITY                 355\n",
       "ARTIST HOME LATITUDE             302\n",
       "ARTIST HOME  LONGITUDE           316\n",
       "KM DISTANCE (HOME - STATION)    1777\n",
       "ALBUM NAME                      2711\n",
       "LABEL NAME                      1125\n",
       "LABEL TYPE                         5\n",
       "LANGUAGE OF MUSIC                 19\n",
       "VISIBLE ETHNIC MINORITY            3\n",
       "CENSUS RACE CLASSIFICATION        20\n",
       "ARTIST GENDER                      9\n",
       "M-MUSIC                            2\n",
       "A-ARTIST                           2\n",
       "P-PERFORMANCE                      2\n",
       "L-LYRICS                           2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION CITY                       1\n",
       "STATION PROVINCE                   1\n",
       "STATION LATITUDE                   1\n",
       "STATION LONGITUDE                 11\n",
       "CHART POSITION                    25\n",
       "ARTIST NAME(S)                     1\n",
       "ARTIST COUNTRY                   395\n",
       "ARTIST HOME CITY                1746\n",
       "ARTIST HOME LATITUDE            1872\n",
       "ARTIST HOME  LONGITUDE          1905\n",
       "KM DISTANCE (HOME - STATION)    1872\n",
       "ALBUM NAME                         1\n",
       "LABEL NAME                         1\n",
       "LABEL TYPE                        33\n",
       "LANGUAGE OF MUSIC                190\n",
       "VISIBLE ETHNIC MINORITY          341\n",
       "CENSUS RACE CLASSIFICATION       340\n",
       "ARTIST GENDER                    288\n",
       "M-MUSIC                          188\n",
       "A-ARTIST                         188\n",
       "P-PERFORMANCE                    188\n",
       "L-LYRICS                         191\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.isna().sum()[clean_df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean 'WEEK OF' to datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2006-01-10 00:00:00\n",
       "1        2006-01-10 00:00:00\n",
       "2        2006-01-10 00:00:00\n",
       "3        2006-01-10 00:00:00\n",
       "4        2006-01-10 00:00:00\n",
       "                ...         \n",
       "35854               3/2/1010\n",
       "35855               3/2/1010\n",
       "35856               3/2/1010\n",
       "35857               3/2/1010\n",
       "35858               3/2/1010\n",
       "Name: WEEK OF, Length: 35859, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['WEEK OF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2006-01-10\n",
       "1        2006-01-10\n",
       "2        2006-01-10\n",
       "3        2006-01-10\n",
       "4        2006-01-10\n",
       "            ...    \n",
       "35854      3/2/1010\n",
       "35855      3/2/1010\n",
       "35856      3/2/1010\n",
       "35857      3/2/1010\n",
       "35858      3/2/1010\n",
       "Name: WEEK OF, Length: 35859, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates = clean_df['WEEK OF'].astype(str).str.split().str[0]\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking in the dataset it appears 2010-03-02 is a missing week, which resembles this typo\n",
    "dates = dates.replace('3/2/1010', '2010-03-02')\n",
    "clean_df['WEEK OF'] = pd.to_datetime(dates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Station Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_nans(key:str, columns:list):\n",
    "    \"\"\"Given a key column and a list of columns to fix,\n",
    "    this function will fill in nan values with the assumption\n",
    "    that all values in the columns to fix will be the same\n",
    "    for any given value in the key column.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create list of all given key values that have any samples with nan values in given columns\n",
    "    for key_value in df[(df[columns].transpose().isna().any())][key].unique():\n",
    "        #Create filters\n",
    "        any_nan = (clean_df[columns].transpose().isna().any()) & (clean_df[key] == key_value)\n",
    "        all_nan = (df[columns].transpose().isna().all()) & (df[key] == key_value)\n",
    "        #Get values from a row that contains not nan values\n",
    "        values = df[~all_nan].head(1)[columns].iloc[0]\n",
    "        #Replace nans with values\n",
    "        clean_df.loc[any_nan, columns] = values.tolist()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_nans('STATION', ['STATION CITY',\n",
    "                         'STATION PROVINCE',\n",
    "                         'STATION LATITUDE',\n",
    "                         'STATION LONGITUDE']  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHART POSITION                    25\n",
       "ARTIST NAME(S)                     1\n",
       "ARTIST COUNTRY                   395\n",
       "ARTIST HOME CITY                1746\n",
       "ARTIST HOME LATITUDE            1872\n",
       "ARTIST HOME  LONGITUDE          1905\n",
       "KM DISTANCE (HOME - STATION)    1872\n",
       "ALBUM NAME                         1\n",
       "LABEL NAME                         1\n",
       "LABEL TYPE                        33\n",
       "LANGUAGE OF MUSIC                190\n",
       "VISIBLE ETHNIC MINORITY          341\n",
       "CENSUS RACE CLASSIFICATION       340\n",
       "ARTIST GENDER                    288\n",
       "M-MUSIC                          188\n",
       "A-ARTIST                         188\n",
       "P-PERFORMANCE                    188\n",
       "L-LYRICS                         191\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.isna().sum()[clean_df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Artist Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[datetime.datetime(2007, 7, 17, 0, 0), 'CFUV  ', 'Victoria', 'BC',\n",
       "        48.43, -123.35, 10, nan, '-', nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan]], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['ARTIST NAME(S)'].isna()].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop row with no artist data\n",
    "clean_df = clean_df[~clean_df['ARTIST NAME(S)'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_nans('ARTIST NAME(S)', ['ARTIST HOME CITY',\n",
    "                                'ARTIST HOME LATITUDE',\n",
    "                                'ARTIST HOME  LONGITUDE',\n",
    "                                'VISIBLE ETHNIC MINORITY', \n",
    "                                'CENSUS RACE CLASSIFICATION', \n",
    "                                'ARTIST GENDER',\n",
    "                                'M-MUSIC',\n",
    "                                'A-ARTIST ',\n",
    "                                'P-PERFORMANCE',\n",
    "                                'L-LYRICS'\n",
    "                                ]  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHART POSITION                    25\n",
       "ARTIST COUNTRY                   394\n",
       "ARTIST HOME LATITUDE              53\n",
       "ARTIST HOME  LONGITUDE            53\n",
       "KM DISTANCE (HOME - STATION)    1871\n",
       "LABEL TYPE                        32\n",
       "LANGUAGE OF MUSIC                189\n",
       "VISIBLE ETHNIC MINORITY           88\n",
       "CENSUS RACE CLASSIFICATION        88\n",
       "ARTIST GENDER                     37\n",
       "M-MUSIC                            6\n",
       "A-ARTIST                           6\n",
       "P-PERFORMANCE                      6\n",
       "L-LYRICS                           6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.isna().sum()[clean_df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling remaining nans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['US', 'UK', 'Int', 'Cdn', 'US/CDN', nan, 'int'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['ARTIST COUNTRY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male Group', 'Male', 'Female', 'Mixed Group', 'Male ',\n",
       "       'Female Group', 'male', nan, 'Mixed Group '], dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['ARTIST GENDER'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Yes', 'No', nan], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['VISIBLE ETHNIC MINORITY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Mixed Group', 'White', 'Black', 'Hispanic', 'Asian Other',\n",
       "       'Asian', 'Native Canadian', nan, 'Middle Eastern',\n",
       "       'Native American', 'Unidentified', 'Asian Indian', 'Jewish',\n",
       "       'Romany', 'Other Asian', 'Indian', 'Indian Asian', 'Inuit',\n",
       "       'Metis', 'East Asian'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['CENSUS RACE CLASSIFICATION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'Yes', nan], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['M-MUSIC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns with NO existing category suitable for nan replacement\n",
    "for key in ['ARTIST COUNTRY', 'ARTIST GENDER', 'VISIBLE ETHNIC MINORITY', 'CENSUS RACE CLASSIFICATION']:\n",
    "    clean_df[key].replace(np.nan, 'unknown', inplace=True)\n",
    "# Columns with existing category suitable for nan replacement\n",
    "for key in ['M-MUSIC', 'A-ARTIST ', 'P-PERFORMANCE', 'L-LYRICS']:\n",
    "    clean_df[key].replace(np.nan, 'No', inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lattitude / Longitude:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Geckoturner ', 'Nas & Damian Marley ', 'Non + Herrmutt Lobby '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[clean_df['ARTIST HOME LATITUDE'].isna()]['ARTIST NAME(S)'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Spain', 'New York, NY/Kingston, JAMAICA',\n",
       "       'Los Angeles, CA/Belgium'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df[clean_df['ARTIST HOME LATITUDE'].isna()]['ARTIST HOME CITY'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_location_columns = ['ARTIST HOME LATITUDE', 'ARTIST HOME  LONGITUDE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'Spain' with coordinates of Madrid\n",
    "values = [40.416775 , -3.703790]\n",
    "clean_df.loc[clean_df['ARTIST NAME(S)'] == 'Geckoturner ', home_location_columns] = values\n",
    "\n",
    "# Replace 'New York, NY/Kingston, JAMAICA' with New York\n",
    "values = clean_df.loc[clean_df['ARTIST HOME CITY'].str.contains('New York'), home_location_columns].head(1).iloc[0].to_list()\n",
    "clean_df.loc[clean_df['ARTIST NAME(S)'] == 'Nas & Damian Marley ', home_location_columns] = values\n",
    "\n",
    "# Replace 'Los Angeles, CA/Belgium' with Los Angeles\n",
    "values = clean_df.loc[clean_df['ARTIST HOME CITY'].str.contains('Los Angeles'), home_location_columns].head(1).iloc[0].to_list()\n",
    "clean_df.loc[clean_df['ARTIST NAME(S)'] == 'Non + Herrmutt Lobby ', home_location_columns] = values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHART POSITION                    25\n",
       "KM DISTANCE (HOME - STATION)    1871\n",
       "LABEL TYPE                        32\n",
       "LANGUAGE OF MUSIC                189\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.isna().sum()[clean_df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean album infromation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_nans('ALBUM NAME', ['LANGUAGE OF MUSIC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "replace_nans('LABEL NAME', ['LABEL TYPE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHART POSITION                    25\n",
       "KM DISTANCE (HOME - STATION)    1871\n",
       "LABEL TYPE                        21\n",
       "LANGUAGE OF MUSIC                177\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.isna().sum()[clean_df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For language matches that could not be made with albums, match with artists instead\n",
    "replace_nans('ARTIST NAME(S)',['LANGUAGE OF MUSIC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CHART POSITION                    25\n",
       "KM DISTANCE (HOME - STATION)    1871\n",
       "LABEL TYPE                        21\n",
       "LANGUAGE OF MUSIC                 81\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.isna().sum()[clean_df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Indie', 'Major', 'Self', nan, 'indie', 'English'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['LABEL TYPE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['LABEL TYPE'].replace(np.nan, 'unknown', inplace=True)\n",
    "#Consulting the dataframe, 'English' is a singular typo\n",
    "clean_df['LABEL TYPE'].replace('English', 'indie', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['English', 'French', nan, 'Multi', 'Spanish', 'Portuguese',\n",
       "       'English/Patois', 'Basque', 'Other', 'english', 'English/Arabic',\n",
       "       'German', 'other', 'e', 'English/Zulu', 'English/French', 'Yes',\n",
       "       'Various', 'Punjabi', 'Creole'], dtype=object)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['LANGUAGE OF MUSIC'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['LANGUAGE OF MUSIC'].replace(np.nan, 'unknown', inplace=True)\n",
    "clean_df['LANGUAGE OF MUSIC'].replace('e', 'english', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4.,  5.,  7.,  8.,  9., 10.,  3.,  2.,  6.,  1., nan])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df['CHART POSITION'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552      Psyche Origami \n",
       "1179          Aceyalone \n",
       "2063    Dilated Peoples \n",
       "3048          Jay Bizzy \n",
       "Name: ARTIST NAME(S), dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nan_filter = clean_df['CHART POSITION'].isna()\n",
    "artists_with_nan_chart_numbers = clean_df[ nan_filter]['ARTIST NAME(S)']\n",
    "artists_with_nan_chart_numbers.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "882      4.0\n",
       "1031     2.0\n",
       "1039     4.0\n",
       "1067    10.0\n",
       "1161     2.0\n",
       "1169     3.0\n",
       "1179     NaN\n",
       "1199    10.0\n",
       "1232     7.0\n",
       "1242     6.0\n",
       "Name: CHART POSITION, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.loc[clean_df['ARTIST NAME(S)'] == 'Aceyalone ', 'CHART POSITION'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace nan values in chart numbers with average chart position held by artist\n",
    "for name in artists_with_nan_chart_numbers:\n",
    "    values = clean_df.loc[clean_df['ARTIST NAME(S)'] == name, 'CHART POSITION']\n",
    "    values.replace(np.nan, int(values.mean()), inplace=True)\n",
    "    clean_df.loc[clean_df['ARTIST NAME(S)'] == name, 'CHART POSITION'] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['CHART POSITION'] = clean_df['CHART POSITION'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean station -> artist distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine(row:pd.Series) -> float:\n",
    "    X = [math.radians(row[0]), math.radians(row[1])]\n",
    "    Y = [math.radians(row[2]), math.radians(row[3])]\n",
    "    return (haversine_distances([X,Y]) * 6371)[0][1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['KM DISTANCE (HOME - STATION)'] = clean_df[['STATION LATITUDE', \n",
    "                                                     'STATION LONGITUDE', \n",
    "                                                     'ARTIST HOME LATITUDE', \n",
    "                                                     'ARTIST HOME  LONGITUDE']\n",
    "                                                    ].apply(haversine, axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], dtype: int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.isna().sum()[clean_df.isna().sum() > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean extra spaces from column names\n",
    "clean_df.columns = clean_df.columns.str.strip()\n",
    "clean_df.columns = clean_df.columns.str.replace('\\s+', ' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean string values\n",
    "string_columns = clean_df.select_dtypes(exclude=[np.number, np.datetime64]).columns\n",
    "\n",
    "for column in string_columns:\n",
    "    cleaned = clean_df[column].astype(str)\n",
    "    cleaned = cleaned.str.strip()\n",
    "    cleaned = cleaned.str.replace('\\s+', ' ', regex=True)\n",
    "    cleaned = cleaned.str.lower()\n",
    "    \n",
    "    clean_df[column] = cleaned\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add canadian-content status (met by having at least 2 MAPL ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.rename(columns={\"M-MUSIC\":\"M\", \"A-ARTIST\": \"A\", \"P-PERFORMANCE\":\"P\",\"L-LYRICS\":\"L\"}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_can_con(row:pd.Series) -> str:\n",
    "    \"\"\"Given row containing M A L P, determines\n",
    "    Canadian Content status\n",
    "    \"\"\"\n",
    "    if row.str.count(\"yes\").sum() >=2:\n",
    "        return 'yes'\n",
    "    else:\n",
    "        return 'no'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['CANADIAN CONTENT'] = clean_df[['M','A','L','P']].apply(is_can_con, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_csv('clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WEEK OF</th>\n",
       "      <th>STATION</th>\n",
       "      <th>STATION CITY</th>\n",
       "      <th>STATION PROVINCE</th>\n",
       "      <th>STATION LATITUDE</th>\n",
       "      <th>STATION LONGITUDE</th>\n",
       "      <th>CHART POSITION</th>\n",
       "      <th>ARTIST NAME(S)</th>\n",
       "      <th>ARTIST COUNTRY</th>\n",
       "      <th>ARTIST HOME CITY</th>\n",
       "      <th>...</th>\n",
       "      <th>LABEL TYPE</th>\n",
       "      <th>LANGUAGE OF MUSIC</th>\n",
       "      <th>VISIBLE ETHNIC MINORITY</th>\n",
       "      <th>CENSUS RACE CLASSIFICATION</th>\n",
       "      <th>ARTIST GENDER</th>\n",
       "      <th>M</th>\n",
       "      <th>A</th>\n",
       "      <th>P</th>\n",
       "      <th>L</th>\n",
       "      <th>CANADIAN CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>cjsr</td>\n",
       "      <td>edmonton</td>\n",
       "      <td>ab</td>\n",
       "      <td>53.55</td>\n",
       "      <td>-113.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>breakestra</td>\n",
       "      <td>us</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>...</td>\n",
       "      <td>indie</td>\n",
       "      <td>english</td>\n",
       "      <td>yes</td>\n",
       "      <td>mixed group</td>\n",
       "      <td>male group</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>cjsr</td>\n",
       "      <td>edmonton</td>\n",
       "      <td>ab</td>\n",
       "      <td>53.55</td>\n",
       "      <td>-113.50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>candy's .22</td>\n",
       "      <td>us</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>...</td>\n",
       "      <td>indie</td>\n",
       "      <td>english</td>\n",
       "      <td>no</td>\n",
       "      <td>white</td>\n",
       "      <td>male group</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>cjsr</td>\n",
       "      <td>edmonton</td>\n",
       "      <td>ab</td>\n",
       "      <td>53.55</td>\n",
       "      <td>-113.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>dangerdoom</td>\n",
       "      <td>us</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>...</td>\n",
       "      <td>indie</td>\n",
       "      <td>english</td>\n",
       "      <td>yes</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>cjsr</td>\n",
       "      <td>edmonton</td>\n",
       "      <td>ab</td>\n",
       "      <td>53.55</td>\n",
       "      <td>-113.50</td>\n",
       "      <td>8.0</td>\n",
       "      <td>blockhead</td>\n",
       "      <td>us</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>...</td>\n",
       "      <td>indie</td>\n",
       "      <td>english</td>\n",
       "      <td>no</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>cjsr</td>\n",
       "      <td>edmonton</td>\n",
       "      <td>ab</td>\n",
       "      <td>53.55</td>\n",
       "      <td>-113.50</td>\n",
       "      <td>9.0</td>\n",
       "      <td>blackalicious</td>\n",
       "      <td>us</td>\n",
       "      <td>sacramento, ca</td>\n",
       "      <td>...</td>\n",
       "      <td>indie</td>\n",
       "      <td>english</td>\n",
       "      <td>yes</td>\n",
       "      <td>black</td>\n",
       "      <td>male group</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>cjsr</td>\n",
       "      <td>edmonton</td>\n",
       "      <td>ab</td>\n",
       "      <td>53.55</td>\n",
       "      <td>-113.50</td>\n",
       "      <td>10.0</td>\n",
       "      <td>onry ozzborn</td>\n",
       "      <td>us</td>\n",
       "      <td>seattle, wa</td>\n",
       "      <td>...</td>\n",
       "      <td>indie</td>\n",
       "      <td>english</td>\n",
       "      <td>yes</td>\n",
       "      <td>hispanic</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>cjsw</td>\n",
       "      <td>calgary</td>\n",
       "      <td>ab</td>\n",
       "      <td>51.08</td>\n",
       "      <td>-114.08</td>\n",
       "      <td>3.0</td>\n",
       "      <td>various</td>\n",
       "      <td>us</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>...</td>\n",
       "      <td>indie</td>\n",
       "      <td>english</td>\n",
       "      <td>yes</td>\n",
       "      <td>mixed group</td>\n",
       "      <td>male group</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>cjsw</td>\n",
       "      <td>calgary</td>\n",
       "      <td>ab</td>\n",
       "      <td>51.08</td>\n",
       "      <td>-114.08</td>\n",
       "      <td>5.0</td>\n",
       "      <td>psyche origami</td>\n",
       "      <td>us</td>\n",
       "      <td>atlanta, ga</td>\n",
       "      <td>...</td>\n",
       "      <td>indie</td>\n",
       "      <td>english</td>\n",
       "      <td>yes</td>\n",
       "      <td>mixed group</td>\n",
       "      <td>male group</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>cjsw</td>\n",
       "      <td>calgary</td>\n",
       "      <td>ab</td>\n",
       "      <td>51.08</td>\n",
       "      <td>-114.08</td>\n",
       "      <td>7.0</td>\n",
       "      <td>various</td>\n",
       "      <td>us</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>...</td>\n",
       "      <td>indie</td>\n",
       "      <td>english</td>\n",
       "      <td>yes</td>\n",
       "      <td>mixed group</td>\n",
       "      <td>male group</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>cjsw</td>\n",
       "      <td>calgary</td>\n",
       "      <td>ab</td>\n",
       "      <td>51.08</td>\n",
       "      <td>-114.08</td>\n",
       "      <td>8.0</td>\n",
       "      <td>mike ladd</td>\n",
       "      <td>us</td>\n",
       "      <td>boston, mass</td>\n",
       "      <td>...</td>\n",
       "      <td>indie</td>\n",
       "      <td>english</td>\n",
       "      <td>yes</td>\n",
       "      <td>black</td>\n",
       "      <td>male group</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     WEEK OF STATION STATION CITY STATION PROVINCE  STATION LATITUDE  \\\n",
       "0 2006-01-10    cjsr     edmonton               ab             53.55   \n",
       "1 2006-01-10    cjsr     edmonton               ab             53.55   \n",
       "2 2006-01-10    cjsr     edmonton               ab             53.55   \n",
       "3 2006-01-10    cjsr     edmonton               ab             53.55   \n",
       "4 2006-01-10    cjsr     edmonton               ab             53.55   \n",
       "5 2006-01-10    cjsr     edmonton               ab             53.55   \n",
       "6 2006-01-10    cjsw      calgary               ab             51.08   \n",
       "7 2006-01-10    cjsw      calgary               ab             51.08   \n",
       "8 2006-01-10    cjsw      calgary               ab             51.08   \n",
       "9 2006-01-10    cjsw      calgary               ab             51.08   \n",
       "\n",
       "   STATION LONGITUDE  CHART POSITION  ARTIST NAME(S) ARTIST COUNTRY  \\\n",
       "0            -113.50             4.0      breakestra             us   \n",
       "1            -113.50             5.0     candy's .22             us   \n",
       "2            -113.50             7.0      dangerdoom             us   \n",
       "3            -113.50             8.0       blockhead             us   \n",
       "4            -113.50             9.0   blackalicious             us   \n",
       "5            -113.50            10.0    onry ozzborn             us   \n",
       "6            -114.08             3.0         various             us   \n",
       "7            -114.08             5.0  psyche origami             us   \n",
       "8            -114.08             7.0         various             us   \n",
       "9            -114.08             8.0       mike ladd             us   \n",
       "\n",
       "  ARTIST HOME CITY  ...  LABEL TYPE  LANGUAGE OF MUSIC  \\\n",
       "0  los angeles, ca  ...       indie            english   \n",
       "1  los angeles, ca  ...       indie            english   \n",
       "2     new york, ny  ...       indie            english   \n",
       "3     new york, ny  ...       indie            english   \n",
       "4   sacramento, ca  ...       indie            english   \n",
       "5      seattle, wa  ...       indie            english   \n",
       "6  los angeles, ca  ...       indie            english   \n",
       "7      atlanta, ga  ...       indie            english   \n",
       "8  los angeles, ca  ...       indie            english   \n",
       "9     boston, mass  ...       indie            english   \n",
       "\n",
       "   VISIBLE ETHNIC MINORITY CENSUS RACE CLASSIFICATION ARTIST GENDER   M   A  \\\n",
       "0                      yes                mixed group    male group  no  no   \n",
       "1                       no                      white    male group  no  no   \n",
       "2                      yes                      black          male  no  no   \n",
       "3                       no                      white          male  no  no   \n",
       "4                      yes                      black    male group  no  no   \n",
       "5                      yes                   hispanic          male  no  no   \n",
       "6                      yes                mixed group    male group  no  no   \n",
       "7                      yes                mixed group    male group  no  no   \n",
       "8                      yes                mixed group    male group  no  no   \n",
       "9                      yes                      black    male group  no  no   \n",
       "\n",
       "    P   L CANADIAN CONTENT  \n",
       "0  no  no               no  \n",
       "1  no  no               no  \n",
       "2  no  no               no  \n",
       "3  no  no               no  \n",
       "4  no  no               no  \n",
       "5  no  no               no  \n",
       "6  no  no               no  \n",
       "7  no  no               no  \n",
       "8  no  no               no  \n",
       "9  no  no               no  \n",
       "\n",
       "[10 rows x 25 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fe28adbe6d40c82bdde6a2233f025e3b944121e67b5abb397657075ce1366ca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('lighthouse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
