{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from helper_functions import *\n",
    "from constants import *\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "- remove empty column\n",
    "- clean column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/owen/Programs/anaconda3/envs/lighthouse/lib/python3.8/site-packages/openpyxl/worksheet/_reader.py:312: UserWarning: Unknown extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_of</th>\n",
       "      <th>station</th>\n",
       "      <th>station_city</th>\n",
       "      <th>station_province</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "      <th>chart_position</th>\n",
       "      <th>artist_name(s)</th>\n",
       "      <th>artist_country</th>\n",
       "      <th>artist_home_city</th>\n",
       "      <th>...</th>\n",
       "      <th>label_name</th>\n",
       "      <th>label_type</th>\n",
       "      <th>language_of_music</th>\n",
       "      <th>visible_ethnic_minority</th>\n",
       "      <th>census_race_classification</th>\n",
       "      <th>artist_gender</th>\n",
       "      <th>m_music</th>\n",
       "      <th>a_artist</th>\n",
       "      <th>p_performance</th>\n",
       "      <th>l_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-10 00:00:00</td>\n",
       "      <td>CJSR</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>AB</td>\n",
       "      <td>53.55</td>\n",
       "      <td>-113.5</td>\n",
       "      <td>4</td>\n",
       "      <td>Breakestra</td>\n",
       "      <td>US</td>\n",
       "      <td>Los Angeles, CA</td>\n",
       "      <td>...</td>\n",
       "      <td>Ubiquity</td>\n",
       "      <td>Indie</td>\n",
       "      <td>English</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Mixed Group</td>\n",
       "      <td>Male Group</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               week_of station station_city station_province  \\\n",
       "0  2006-01-10 00:00:00    CJSR     Edmonton               AB   \n",
       "\n",
       "   station_latitude  station_longitude chart_position artist_name(s)  \\\n",
       "0             53.55             -113.5              4    Breakestra    \n",
       "\n",
       "  artist_country artist_home_city  ... label_name label_type  \\\n",
       "0             US  Los Angeles, CA  ...   Ubiquity      Indie   \n",
       "\n",
       "   language_of_music visible_ethnic_minority census_race_classification  \\\n",
       "0            English                     Yes                Mixed Group   \n",
       "\n",
       "  artist_gender m_music a_artist p_performance l_lyrics  \n",
       "0    Male Group      No       No            No       No  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"data/Canadian Radio Playlist_V.21.xlsx\", \"Campus Radio Charts\")\n",
    "df.drop('Unnamed: 24', axis=1, inplace=True)   # Drop empty colummn\n",
    "df.columns = [re.sub('\\s-\\s|\\s+|-', '_',x.lower().strip()) for x in df.columns]  #Clean column names\n",
    "\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strings\n",
    "- remove extra white spaces\n",
    "- lowercase\n",
    "- convert placeholders to nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = df.applymap(lambda s: re.sub('\\s+',' ',s.strip().lower()) if type(s) == str else s)\n",
    "df.replace(PLACEHOLDERS, np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date Times\n",
    "\n",
    "- Change '3/2/1010' to '2010-03-02'\n",
    "- Convert to datetime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['week_of'] == '3/2/1010', 'week_of'] = '2010-03-02'\n",
    "df['week_of'] = pd.to_datetime(df['week_of'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change home cities with multiple entries to be only the first entry\n",
    "- example: \"Toronto, Canada/Kingston, Jamaica\" would become \"Toronto, Canada\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['artist_home_city'] = df['artist_home_city'].str.split('/').str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split 'various' artists into unique groupings\n",
    "- although the artists are not known, those with the same demographic features and locations are grouped and considered the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = make_unique(df,'artist_name(s)',VALUE_EXCEPTIONS,ARTIST_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synchronize Data by key identifiers\n",
    "- 'identifiers' in this case are Artist Name, Station Name, or Album Name.  It is  assumed than the corresponding information to these identifiers should always be the same.\n",
    "- Remove any records with missing identifiers\n",
    "- Ensure that each instance of a station, artist, or ablum always has the same corresponding information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['artist_name(s)'].isna()]\n",
    "df = df[~df['station'].isna()]\n",
    "df = df[~df['album_name'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 334/334 [00:02<00:00, 120.51it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 148.93it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 68.64it/s]\n",
      "100%|██████████| 2058/2058 [01:05<00:00, 31.27it/s]\n",
      "100%|██████████| 2673/2673 [00:23<00:00, 115.57it/s]\n"
     ]
    }
   ],
   "source": [
    "df = syncrhonize_data(df, 'artist_home_city', ['artist_home_latitude', 'artist_home_longitude','artist_country'])\n",
    "df = syncrhonize_data(df, 'station_city', ['station_latitude', 'station_longitude'])\n",
    "df = syncrhonize_data(df, 'station', STATION_COLUMNS)\n",
    "df = syncrhonize_data(df, 'artist_name(s)', ARTIST_COLUMNS)\n",
    "df = syncrhonize_data(df, 'album_name', ALBUM_COLUMNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace nans in string columns with 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.select_dtypes(exclude=np.number).columns] = df.select_dtypes(exclude=np.number).fillna('unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Give lattitude and longitude to locations without them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_country</th>\n",
       "      <th>artist_home_city</th>\n",
       "      <th>artist_home_latitude</th>\n",
       "      <th>artist_home_longitude</th>\n",
       "      <th>visible_ethnic_minority</th>\n",
       "      <th>census_race_classification</th>\n",
       "      <th>artist_gender</th>\n",
       "      <th>m_music</th>\n",
       "      <th>a_artist</th>\n",
       "      <th>p_performance</th>\n",
       "      <th>l_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7526</th>\n",
       "      <td>us</td>\n",
       "      <td>california</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8593</th>\n",
       "      <td>int</td>\n",
       "      <td>germany</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>white</td>\n",
       "      <td>male group</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14606</th>\n",
       "      <td>int</td>\n",
       "      <td>spain</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18732</th>\n",
       "      <td>int</td>\n",
       "      <td>jamaica</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>black</td>\n",
       "      <td>mixed group</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23036</th>\n",
       "      <td>int</td>\n",
       "      <td>france</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28442</th>\n",
       "      <td>cdn</td>\n",
       "      <td>fort mcmurray, ab</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist_country   artist_home_city  artist_home_latitude  \\\n",
       "7526              us         california                   NaN   \n",
       "8593             int            germany                   NaN   \n",
       "14606            int              spain                   NaN   \n",
       "18732            int            jamaica                   NaN   \n",
       "23036            int             france                   NaN   \n",
       "28442            cdn  fort mcmurray, ab                   NaN   \n",
       "\n",
       "       artist_home_longitude visible_ethnic_minority  \\\n",
       "7526                     NaN                     yes   \n",
       "8593                     NaN                      no   \n",
       "14606                    NaN                      no   \n",
       "18732                    NaN                     yes   \n",
       "23036                    NaN                      no   \n",
       "28442                    NaN                      no   \n",
       "\n",
       "      census_race_classification artist_gender m_music a_artist p_performance  \\\n",
       "7526                       black          male      no       no            no   \n",
       "8593                       white    male group      no       no            no   \n",
       "14606                      white          male      no       no            no   \n",
       "18732                      black   mixed group      no       no            no   \n",
       "23036                      white          male      no       no            no   \n",
       "28442                      white          male     yes      yes           yes   \n",
       "\n",
       "      l_lyrics  \n",
       "7526        no  \n",
       "8593        no  \n",
       "14606       no  \n",
       "18732       no  \n",
       "23036       no  \n",
       "28442      yes  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df[~(df['artist_home_city'] == 'unknown') & df['artist_home_latitude'].isna()][ARTIST_COLUMNS].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = assign_lat_long(df, 'fort mcmurray, ab', 56.72, -111.37)\n",
    "df = assign_lat_long(df, 'california', 36.77, -119.41) #Center of state\n",
    "df = assign_lat_long(df, 'germany', 52.52, 13.40) # Berlin\n",
    "df = assign_lat_long(df, 'spain', 40.41, -3.70) #Madrid\n",
    "df = assign_lat_long(df, 'jamaica', 18.01, -76.80) #Kingston\n",
    "df = assign_lat_long(df, 'france', 48.85, 2.35) #Paris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender values\n",
    "- remove group designation from gender and create new column to identify groups from solo artists\n",
    "- fit all values into 'male, 'mixed', 'female', 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male            20180\n",
       "male group      11765\n",
       "mixed group      2214\n",
       "female           1316\n",
       "unknown           285\n",
       "female group       97\n",
       "no                  1\n",
       "Name: artist_gender, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist_gender'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male       31945\n",
       "mixed       2214\n",
       "female      1413\n",
       "unknown      286\n",
       "Name: artist_gender, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist_is_group'] = df['artist_gender'].str.contains('group')\n",
    "df['artist_gender'].replace('male group', 'male', inplace=True)\n",
    "df['artist_gender'].replace('mixed group', 'mixed', inplace=True)\n",
    "df['artist_gender'].replace('female group', 'female', inplace=True)\n",
    "df['artist_gender'].replace('no', 'unknown', inplace=True)\n",
    "df['artist_gender'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visible ethnic minority values\n",
    "- one instance of \"black\" is changed to \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes        23965\n",
       "no         11555\n",
       "unknown      337\n",
       "black          1\n",
       "Name: visible_ethnic_minority, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['visible_ethnic_minority'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes        23966\n",
       "no         11555\n",
       "unknown      337\n",
       "Name: visible_ethnic_minority, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['visible_ethnic_minority'].replace('black','yes', inplace=True)\n",
    "df['visible_ethnic_minority'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Census race classification values\n",
    "- consolidate similar classifcations into more general categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "black              15445\n",
       "white              11546\n",
       "mixed group         6692\n",
       "hispanic             499\n",
       "asian                406\n",
       "middle eastern       342\n",
       "unknown              337\n",
       "native canadian      160\n",
       "asian indian         132\n",
       "unidentified          68\n",
       "other asian           66\n",
       "indian asian          48\n",
       "jewish                38\n",
       "asian other           24\n",
       "native american       21\n",
       "inuit                 19\n",
       "metis                  7\n",
       "romany                 3\n",
       "east asian             3\n",
       "indian                 1\n",
       "male                   1\n",
       "Name: census_race_classification, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['census_race_classification'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "black              15445\n",
       "white              11546\n",
       "mixed group         6692\n",
       "hispanic             499\n",
       "asian                499\n",
       "unknown              406\n",
       "middle eastern       342\n",
       "native american      207\n",
       "indian               181\n",
       "jewish                38\n",
       "romany                 3\n",
       "Name: census_race_classification, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['census_race_classification'].replace(['male','unidentified'], 'unknown', inplace=True)\n",
    "df['census_race_classification'].replace(['asian other','other asian', 'east asian'],'asian', inplace=True)\n",
    "df['census_race_classification'].replace(['asian indian','indian asian'],'indian', inplace=True)\n",
    "df['census_race_classification'].replace(['native canadian','native american', 'inuit', 'metis'],'native american', inplace=True)\n",
    "df['census_race_classification'].value_counts(dropna=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label type\n",
    "- replace one instance of 'english' to 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indie      27413\n",
       "major       5027\n",
       "self        3388\n",
       "unknown       29\n",
       "english        1\n",
       "Name: label_type, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "indie      27413\n",
       "major       5027\n",
       "self        3388\n",
       "unknown       30\n",
       "Name: label_type, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label_type'].replace(['english',np.nan], 'unknown', inplace=True)\n",
    "df['label_type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language of music\n",
    "- consolidate classifications with multiple langues into 'multiple languages'\n",
    "- consolidate unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english           34879\n",
       "french              610\n",
       "unknown             186\n",
       "multi                72\n",
       "english/arabic       38\n",
       "spanish              20\n",
       "english/french       13\n",
       "other                 9\n",
       "german                8\n",
       "creole                5\n",
       "english/patois        4\n",
       "english/zulu          4\n",
       "portuguese            4\n",
       "basque                3\n",
       "yes                   1\n",
       "various               1\n",
       "punjabi               1\n",
       "Name: language_of_music, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['language_of_music'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "english               34879\n",
       "french                  610\n",
       "unknown                 196\n",
       "multiple languages      132\n",
       "spanish                  20\n",
       "german                    8\n",
       "creole                    5\n",
       "portuguese                4\n",
       "basque                    3\n",
       "punjabi                   1\n",
       "Name: language_of_music, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiple_languages = [  'english/arabic', \n",
    "                        'english/french', \n",
    "                        'english/patois',\n",
    "                        'english/zulu', \n",
    "                        'various',\n",
    "                        'multi']\n",
    "df['language_of_music'].replace(multiple_languages, 'multiple languages', inplace= True)\n",
    "df['language_of_music'].replace(['yes','other',np.nan], 'unknown', inplace= True)\n",
    "df['language_of_music'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distance\n",
    "\n",
    "- calculate haversine distance where missing and it is possible to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    33987\n",
       "True      1871\n",
       "Name: km_distance_(home_station), dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['km_distance_(home_station)'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_filter = df['km_distance_(home_station)'].isna() & ~df['artist_home_latitude'].isna()\n",
    "df.loc[row_filter, 'km_distance_(home_station)'] = haversine(df[row_filter]['station_latitude'],\n",
    "                                                             df[row_filter]['station_longitude'], \n",
    "                                                             df[row_filter]['artist_home_latitude'],\n",
    "                                                             df[row_filter]['artist_home_longitude'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    34117\n",
       "True      1741\n",
       "Name: km_distance_(home_station), dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['km_distance_(home_station)'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add canadian-content status (met by having at least 2 MAPL ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['canadian_content'] = (df[['m_music','a_artist','l_lyrics','p_performance']] == 'yes').sum(axis=1) >=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add station_province column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['edmonton', 'calgary', 'lethbridge', 'victoria', 'burnaby',\n",
       "       'winnipeg', 'halifax', 'toronto', 'mississauga', 'london',\n",
       "       'ottawa', 'thunder bay', 'montreal', 'kamloops', 'guelph',\n",
       "       'saint john', 'windsor', 'fredericton', 'laval', 'nanaimo',\n",
       "       'smithers'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['station_city'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_dictionary = {\n",
    "                        'edmonton' : 'alberta',\n",
    "                        'calgary' : 'alberta',\n",
    "                        'lethbridge': 'alberta',\n",
    "                        'victoria' : 'british columbia',\n",
    "                        'burnaby' : 'british columbia',\n",
    "                        'winnipeg' : 'manitoba',\n",
    "                        'halifax' : 'nova scotia',\n",
    "                        'toronto' : 'ontario',\n",
    "                        'mississauga' : 'ontario',\n",
    "                        'london' : 'ontario',\n",
    "                        'ottawa' : 'ontario',\n",
    "                        'thunder bay' : 'ontario',\n",
    "                        'montreal' : 'quebec',\n",
    "                        'kamloops' : 'british columbia',\n",
    "                        'guelph' : 'ontario',\n",
    "                        'saint john' : 'new brunswick',\n",
    "                        'windsor' : 'ontario',\n",
    "                        'fredericton' : 'new brunswick',\n",
    "                        'laval' : 'quebec',\n",
    "                        'nanaimo' : 'british columbia',\n",
    "                        'smithers' : 'british columbia'\n",
    "                        }\n",
    "\n",
    "df['station_province'] = df['station_city'].map(province_dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ontario             0.403229\n",
       "alberta             0.170673\n",
       "quebec              0.166769\n",
       "british columbia    0.153355\n",
       "manitoba            0.066373\n",
       "nova scotia         0.021752\n",
       "new brunswick       0.017848\n",
       "Name: station_province, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['station_province'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_dictionary = {\n",
    "                        'edmonton' : 932550,\n",
    "                        'calgary' : 1239000,\n",
    "                        'lethbridge': 92730,\n",
    "                        'victoria' : 85795,\n",
    "                        'burnaby' : 232755,\n",
    "                        'winnipeg' : 705245,\n",
    "                        'halifax' : 403130,\n",
    "                        'toronto' : 2732000,\n",
    "                        'mississauga' : 721600,\n",
    "                        'london' : 383825,\n",
    "                        'ottawa' : 934240,\n",
    "                        'thunder bay' : 107910,\n",
    "                        'montreal' : 1705000,\n",
    "                        'kamloops' : 90280,\n",
    "                        'guelph' : 131795,\n",
    "                        'saint john' : 67575,\n",
    "                        'windsor' : 217185,\n",
    "                        'fredericton' : 58220,\n",
    "                        'laval' : 422995,\n",
    "                        'nanaimo' : 90505,\n",
    "                        'smithers' : 5351\n",
    "                        }\n",
    "\n",
    "df['city_population'] = df['station_city'].map(population_dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('data/clean_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Station Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['week_of', 'station', 'station_city', 'station_province',\n",
       "       'station_latitude', 'station_longitude', 'chart_position',\n",
       "       'artist_name(s)', 'artist_country', 'artist_home_city',\n",
       "       'artist_home_latitude', 'artist_home_longitude',\n",
       "       'km_distance_(home_station)', 'album_name', 'label_name', 'label_type',\n",
       "       'language_of_music', 'visible_ethnic_minority',\n",
       "       'census_race_classification', 'artist_gender', 'm_music', 'a_artist',\n",
       "       'p_performance', 'l_lyrics', 'artist_is_group', 'canadian_content',\n",
       "       'city_population'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df = df[['station', 'station_city','city_population','station_province','station_latitude','station_longitude']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['total_plays'] = station_df['station'].map(df['station'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['total_artists'] = [ df[df['station'] == x ]['artist_name(s)'].nunique() for x in station_df['station'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['artists_to_plays_ratio'] = station_df['total_artists'] / station_df['total_plays'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['artists_to_population_ratio'] = station_df['total_artists'] / station_df['city_population'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['bipoc_artists'] = [[ df[df['station'] == x ]['visible_ethnic_minority'].value_counts(normalize=True)][0]['yes'] for x in station_df['station'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['canadian_artists'] =  [[ df[df['station'] == x ]['canadian_content'].value_counts(normalize=True)][0][True] for x in station_df['station'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['male_artists'] =  [[ df[df['station'] == x ]['artist_gender'].value_counts(normalize=True)][0]['male'] for x in station_df['station'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df['english_plays'] =  [[ df[df['station'] == x ]['language_of_music'].value_counts(normalize=True)][0]['english'] for x in station_df['station'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>station_city</th>\n",
       "      <th>city_population</th>\n",
       "      <th>station_province</th>\n",
       "      <th>station_latitude</th>\n",
       "      <th>station_longitude</th>\n",
       "      <th>total_plays</th>\n",
       "      <th>total_artists</th>\n",
       "      <th>artists_to_plays_ratio</th>\n",
       "      <th>artists_to_population_ratio</th>\n",
       "      <th>bipoc_artists</th>\n",
       "      <th>canadian_artists</th>\n",
       "      <th>male_artists</th>\n",
       "      <th>english_plays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cjsr</td>\n",
       "      <td>edmonton</td>\n",
       "      <td>932550</td>\n",
       "      <td>alberta</td>\n",
       "      <td>53.55</td>\n",
       "      <td>-113.50</td>\n",
       "      <td>1920</td>\n",
       "      <td>425</td>\n",
       "      <td>0.221354</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.651042</td>\n",
       "      <td>0.432292</td>\n",
       "      <td>0.851562</td>\n",
       "      <td>0.986458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cjsw</td>\n",
       "      <td>calgary</td>\n",
       "      <td>1239000</td>\n",
       "      <td>alberta</td>\n",
       "      <td>51.08</td>\n",
       "      <td>-114.08</td>\n",
       "      <td>1970</td>\n",
       "      <td>505</td>\n",
       "      <td>0.256345</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.661929</td>\n",
       "      <td>0.303553</td>\n",
       "      <td>0.809645</td>\n",
       "      <td>0.955838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ckxu</td>\n",
       "      <td>lethbridge</td>\n",
       "      <td>92730</td>\n",
       "      <td>alberta</td>\n",
       "      <td>49.70</td>\n",
       "      <td>-112.83</td>\n",
       "      <td>2230</td>\n",
       "      <td>539</td>\n",
       "      <td>0.241704</td>\n",
       "      <td>0.005813</td>\n",
       "      <td>0.583408</td>\n",
       "      <td>0.513901</td>\n",
       "      <td>0.885650</td>\n",
       "      <td>0.982960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cfuv</td>\n",
       "      <td>victoria</td>\n",
       "      <td>85795</td>\n",
       "      <td>british columbia</td>\n",
       "      <td>48.43</td>\n",
       "      <td>-123.35</td>\n",
       "      <td>2129</td>\n",
       "      <td>488</td>\n",
       "      <td>0.229216</td>\n",
       "      <td>0.005688</td>\n",
       "      <td>0.705965</td>\n",
       "      <td>0.276186</td>\n",
       "      <td>0.882574</td>\n",
       "      <td>0.984969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cjsf</td>\n",
       "      <td>burnaby</td>\n",
       "      <td>232755</td>\n",
       "      <td>british columbia</td>\n",
       "      <td>49.25</td>\n",
       "      <td>-123.13</td>\n",
       "      <td>1350</td>\n",
       "      <td>301</td>\n",
       "      <td>0.222963</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.729630</td>\n",
       "      <td>0.319259</td>\n",
       "      <td>0.903704</td>\n",
       "      <td>0.988148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station station_city  city_population  station_province  station_latitude  \\\n",
       "0    cjsr     edmonton           932550           alberta             53.55   \n",
       "1    cjsw      calgary          1239000           alberta             51.08   \n",
       "2    ckxu   lethbridge            92730           alberta             49.70   \n",
       "3    cfuv     victoria            85795  british columbia             48.43   \n",
       "4    cjsf      burnaby           232755  british columbia             49.25   \n",
       "\n",
       "   station_longitude  total_plays  total_artists  artists_to_plays_ratio  \\\n",
       "0            -113.50         1920            425                0.221354   \n",
       "1            -114.08         1970            505                0.256345   \n",
       "2            -112.83         2230            539                0.241704   \n",
       "3            -123.35         2129            488                0.229216   \n",
       "4            -123.13         1350            301                0.222963   \n",
       "\n",
       "   artists_to_population_ratio  bipoc_artists  canadian_artists  male_artists  \\\n",
       "0                     0.000456       0.651042          0.432292      0.851562   \n",
       "1                     0.000408       0.661929          0.303553      0.809645   \n",
       "2                     0.005813       0.583408          0.513901      0.885650   \n",
       "3                     0.005688       0.705965          0.276186      0.882574   \n",
       "4                     0.001293       0.729630          0.319259      0.903704   \n",
       "\n",
       "   english_plays  \n",
       "0       0.986458  \n",
       "1       0.955838  \n",
       "2       0.982960  \n",
       "3       0.984969  \n",
       "4       0.988148  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "station_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "station_df.to_csv('data/clean_data_stations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artist Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['week_of', 'station', 'station_city', 'station_province',\n",
       "       'station_latitude', 'station_longitude', 'chart_position',\n",
       "       'artist_name(s)', 'artist_country', 'artist_home_city',\n",
       "       'artist_home_latitude', 'artist_home_longitude',\n",
       "       'km_distance_(home_station)', 'album_name', 'label_name', 'label_type',\n",
       "       'language_of_music', 'visible_ethnic_minority',\n",
       "       'census_race_classification', 'artist_gender', 'm_music', 'a_artist',\n",
       "       'p_performance', 'l_lyrics', 'artist_is_group', 'canadian_content',\n",
       "       'city_population'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df = df[['artist_name(s)', 'artist_country','artist_home_city','visible_ethnic_minority','census_race_classification','artist_gender', 'canadian_content', 'artist_is_group']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df['total_plays'] = artist_df['artist_name(s)'].map(df[['artist_name(s)']].groupby(['artist_name(s)'])['artist_name(s)'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_name(s)</th>\n",
       "      <th>artist_country</th>\n",
       "      <th>artist_home_city</th>\n",
       "      <th>visible_ethnic_minority</th>\n",
       "      <th>census_race_classification</th>\n",
       "      <th>artist_gender</th>\n",
       "      <th>canadian_content</th>\n",
       "      <th>artist_is_group</th>\n",
       "      <th>total_plays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breakestra</td>\n",
       "      <td>us</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>yes</td>\n",
       "      <td>mixed group</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>candy's .22</td>\n",
       "      <td>us</td>\n",
       "      <td>los angeles, ca</td>\n",
       "      <td>no</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dangerdoom</td>\n",
       "      <td>us</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>yes</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>blockhead</td>\n",
       "      <td>us</td>\n",
       "      <td>new york, ny</td>\n",
       "      <td>no</td>\n",
       "      <td>white</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blackalicious</td>\n",
       "      <td>us</td>\n",
       "      <td>sacramento, ca</td>\n",
       "      <td>yes</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2053</th>\n",
       "      <td>various_69</td>\n",
       "      <td>cdn</td>\n",
       "      <td>toronto, on</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>unknown</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2054</th>\n",
       "      <td>lokz</td>\n",
       "      <td>cdn</td>\n",
       "      <td>toronto, on</td>\n",
       "      <td>yes</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2055</th>\n",
       "      <td>shad &amp; dallas</td>\n",
       "      <td>cdn</td>\n",
       "      <td>london, on</td>\n",
       "      <td>yes</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>the happy unfortunate</td>\n",
       "      <td>cdn</td>\n",
       "      <td>winnipeg, mb</td>\n",
       "      <td>yes</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>jaswho?</td>\n",
       "      <td>us</td>\n",
       "      <td>oakland, ca</td>\n",
       "      <td>yes</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2058 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist_name(s) artist_country artist_home_city  \\\n",
       "0                breakestra             us  los angeles, ca   \n",
       "1               candy's .22             us  los angeles, ca   \n",
       "2                dangerdoom             us     new york, ny   \n",
       "3                 blockhead             us     new york, ny   \n",
       "4             blackalicious             us   sacramento, ca   \n",
       "...                     ...            ...              ...   \n",
       "2053             various_69            cdn      toronto, on   \n",
       "2054                   lokz            cdn      toronto, on   \n",
       "2055          shad & dallas            cdn       london, on   \n",
       "2056  the happy unfortunate            cdn     winnipeg, mb   \n",
       "2057                jaswho?             us      oakland, ca   \n",
       "\n",
       "     visible_ethnic_minority census_race_classification artist_gender  \\\n",
       "0                        yes                mixed group          male   \n",
       "1                         no                      white          male   \n",
       "2                        yes                      black          male   \n",
       "3                         no                      white          male   \n",
       "4                        yes                      black          male   \n",
       "...                      ...                        ...           ...   \n",
       "2053                 unknown                    unknown       unknown   \n",
       "2054                     yes                      black          male   \n",
       "2055                     yes                      black          male   \n",
       "2056                     yes                      black          male   \n",
       "2057                     yes                      black          male   \n",
       "\n",
       "      canadian_content  artist_is_group  total_plays  \n",
       "0                False             True           32  \n",
       "1                False             True           10  \n",
       "2                False            False           18  \n",
       "3                False            False           37  \n",
       "4                False             True            2  \n",
       "...                ...              ...          ...  \n",
       "2053             False            False            2  \n",
       "2054              True            False            1  \n",
       "2055              True            False            1  \n",
       "2056              True            False            1  \n",
       "2057             False            False            1  \n",
       "\n",
       "[2058 rows x 9 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df = pd.merge(artist_df, pd.crosstab(df['artist_name(s)'], df['station_province'], normalize='index'), on='artist_name(s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df = pd.concat([artist_df, pd.get_dummies(artist_df[['artist_country', 'visible_ethnic_minority', 'artist_gender']]) ], axis=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_df.to_csv('data/clean_data_artists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['week_of', 'station', 'station_city', 'station_province',\n",
       "       'station_latitude', 'station_longitude', 'chart_position',\n",
       "       'artist_name(s)', 'artist_country', 'artist_home_city',\n",
       "       'artist_home_latitude', 'artist_home_longitude',\n",
       "       'km_distance_(home_station)', 'album_name', 'label_name', 'label_type',\n",
       "       'language_of_music', 'visible_ethnic_minority',\n",
       "       'census_race_classification', 'artist_gender', 'm_music', 'a_artist',\n",
       "       'p_performance', 'l_lyrics', 'artist_is_group', 'canadian_content',\n",
       "       'city_population'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df = df[['week_of']].drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['unique_artists_played'] = [df[df['week_of'] == x ]['artist_name(s)'].nunique() for x in time_df['week_of'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['total_plays'] = [df[df['week_of'] == x ]['artist_name(s)'].count() for x in time_df['week_of'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['bipoc_plays'] = [df[df['week_of'] == x ]['visible_ethnic_minority'].replace(['yes','no','unknown'],[1,0,0]).sum() for x in time_df['week_of'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['male_plays'] = [df[df['week_of'] == x ]['artist_gender'].replace(['male','mixed','female','unknown'],[1,0,0,0]).sum() for x in time_df['week_of'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df['canadian_content_plays'] = [df[df['week_of'] == x ]['canadian_content'].sum() for x in time_df['week_of'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for station in df['station'].unique():\n",
    "    time_df[f'{station}_station_plays'] = [df[(df['week_of'] == x ) & (df['station'] == station)]['artist_name(s)'].count() for x  in time_df['week_of'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "for province in df['station_province'].unique():\n",
    "    time_df[f'{station}_province_plays'] = [df[(df['week_of'] == x ) & (df['station'] == province)]['artist_name(s)'].count() for x  in time_df['week_of'].unique()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>week_of</th>\n",
       "      <th>unique_artists_played</th>\n",
       "      <th>total_plays</th>\n",
       "      <th>bipoc_plays</th>\n",
       "      <th>male_plays</th>\n",
       "      <th>canadian_content_plays</th>\n",
       "      <th>cjsr_station_plays</th>\n",
       "      <th>cjsw_station_plays</th>\n",
       "      <th>ckxu_station_plays</th>\n",
       "      <th>cfuv_station_plays</th>\n",
       "      <th>...</th>\n",
       "      <th>cjam_station_plays</th>\n",
       "      <th>chsr_station_plays</th>\n",
       "      <th>chry_station_plays</th>\n",
       "      <th>cjlo_station_plays</th>\n",
       "      <th>chyz_station_plays</th>\n",
       "      <th>chly_station_plays</th>\n",
       "      <th>cscr_station_plays</th>\n",
       "      <th>cism_station_plays</th>\n",
       "      <th>cick_station_plays</th>\n",
       "      <th>cick_province_plays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-10</td>\n",
       "      <td>80</td>\n",
       "      <td>130</td>\n",
       "      <td>92</td>\n",
       "      <td>119</td>\n",
       "      <td>32</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-17</td>\n",
       "      <td>71</td>\n",
       "      <td>130</td>\n",
       "      <td>86</td>\n",
       "      <td>117</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-24</td>\n",
       "      <td>72</td>\n",
       "      <td>130</td>\n",
       "      <td>82</td>\n",
       "      <td>116</td>\n",
       "      <td>56</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-31</td>\n",
       "      <td>88</td>\n",
       "      <td>150</td>\n",
       "      <td>91</td>\n",
       "      <td>137</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-02-07</td>\n",
       "      <td>53</td>\n",
       "      <td>80</td>\n",
       "      <td>49</td>\n",
       "      <td>72</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>2011-02-08</td>\n",
       "      <td>66</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>102</td>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>2011-02-15</td>\n",
       "      <td>63</td>\n",
       "      <td>120</td>\n",
       "      <td>73</td>\n",
       "      <td>114</td>\n",
       "      <td>74</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>2011-02-22</td>\n",
       "      <td>54</td>\n",
       "      <td>100</td>\n",
       "      <td>59</td>\n",
       "      <td>94</td>\n",
       "      <td>52</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>2011-03-01</td>\n",
       "      <td>55</td>\n",
       "      <td>100</td>\n",
       "      <td>56</td>\n",
       "      <td>95</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>2010-03-02</td>\n",
       "      <td>87</td>\n",
       "      <td>150</td>\n",
       "      <td>91</td>\n",
       "      <td>124</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>267 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       week_of  unique_artists_played  total_plays  bipoc_plays  male_plays  \\\n",
       "0   2006-01-10                     80          130           92         119   \n",
       "1   2006-01-17                     71          130           86         117   \n",
       "2   2006-01-24                     72          130           82         116   \n",
       "3   2006-01-31                     88          150           91         137   \n",
       "4   2006-02-07                     53           80           49          72   \n",
       "..         ...                    ...          ...          ...         ...   \n",
       "262 2011-02-08                     66          110           80         102   \n",
       "263 2011-02-15                     63          120           73         114   \n",
       "264 2011-02-22                     54          100           59          94   \n",
       "265 2011-03-01                     55          100           56          95   \n",
       "266 2010-03-02                     87          150           91         124   \n",
       "\n",
       "     canadian_content_plays  cjsr_station_plays  cjsw_station_plays  \\\n",
       "0                        32                  10                  10   \n",
       "1                        43                   0                  10   \n",
       "2                        56                  10                  10   \n",
       "3                        55                  10                  10   \n",
       "4                        26                  10                  10   \n",
       "..                      ...                 ...                 ...   \n",
       "262                      63                  10                  10   \n",
       "263                      74                  10                  10   \n",
       "264                      52                  10                  10   \n",
       "265                      57                   0                   0   \n",
       "266                      66                   0                  10   \n",
       "\n",
       "     ckxu_station_plays  cfuv_station_plays  ...  cjam_station_plays  \\\n",
       "0                    10                  10  ...                   0   \n",
       "1                    10                  10  ...                   0   \n",
       "2                    10                   0  ...                   0   \n",
       "3                    10                  10  ...                   0   \n",
       "4                    10                  10  ...                   0   \n",
       "..                  ...                 ...  ...                 ...   \n",
       "262                  10                  10  ...                  10   \n",
       "263                  10                  10  ...                  10   \n",
       "264                   0                  10  ...                  10   \n",
       "265                  10                  10  ...                   0   \n",
       "266                  10                  10  ...                  10   \n",
       "\n",
       "     chsr_station_plays  chry_station_plays  cjlo_station_plays  \\\n",
       "0                     0                   0                   0   \n",
       "1                     0                   0                   0   \n",
       "2                     0                   0                   0   \n",
       "3                     0                   0                   0   \n",
       "4                     0                   0                   0   \n",
       "..                  ...                 ...                 ...   \n",
       "262                   0                   0                  10   \n",
       "263                   0                   0                  10   \n",
       "264                   0                   0                  10   \n",
       "265                   0                   0                  10   \n",
       "266                   0                   0                  10   \n",
       "\n",
       "     chyz_station_plays  chly_station_plays  cscr_station_plays  \\\n",
       "0                     0                   0                   0   \n",
       "1                     0                   0                   0   \n",
       "2                     0                   0                   0   \n",
       "3                     0                   0                   0   \n",
       "4                     0                   0                   0   \n",
       "..                  ...                 ...                 ...   \n",
       "262                  10                   0                   0   \n",
       "263                  10                   0                   0   \n",
       "264                  10                   0                   0   \n",
       "265                  10                   0                   0   \n",
       "266                  10                   0                  10   \n",
       "\n",
       "     cism_station_plays  cick_station_plays  cick_province_plays  \n",
       "0                     0                   0                    0  \n",
       "1                     0                   0                    0  \n",
       "2                     0                   0                    0  \n",
       "3                     0                   0                    0  \n",
       "4                     0                   0                    0  \n",
       "..                  ...                 ...                  ...  \n",
       "262                   0                   0                    0  \n",
       "263                   0                   0                    0  \n",
       "264                   0                   0                    0  \n",
       "265                   0                   0                    0  \n",
       "266                  10                   0                    0  \n",
       "\n",
       "[267 rows x 32 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_df.to_csv('data/time_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4fe28adbe6d40c82bdde6a2233f025e3b944121e67b5abb397657075ce1366ca"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('lighthouse')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
